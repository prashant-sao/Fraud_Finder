from flask import Blueprint, jsonify, request, render_template
from flask_security import auth_required, current_user, login_user
from sqlalchemy import func
from werkzeug.security import check_password_hash
from application.database import db
from application.models import (
    User, Job_Posting, Analysis_Results, 
    Fraud_Indicators, Company_Verification, Community_Reports,
    Trending_Fraud_Job
)
import requests
from bs4 import BeautifulSoup
import re
import logging
from datetime import datetime
import json
from functools import wraps
from urllib.parse import urlparse

# Import fraud detection systems
from application.agent.corporate_agent import CorporateAgent
from application.agent.auto_reply import generate_auto_reply
from application.agent.scam_checker import add_scam_to_database
from application.agent.risk_score import JobFraudDetector

api_bp = Blueprint('api_bp', __name__)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize detectors (single initialization)
corporate_agent = None
job_fraud_detector = None

def init_detectors():
    global corporate_agent, job_fraud_detector
    if corporate_agent is None:
        corporate_agent = CorporateAgent()
    if job_fraud_detector is None:
        job_fraud_detector = JobFraudDetector()

def validate_json_request(required_fields=None):
    """Decorator to validate JSON requests"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            data = request.get_json()
            if not data:
                return jsonify({'error': 'No JSON data provided'}), 400
            
            if required_fields:
                missing = [field for field in required_fields if not data.get(field)]
                if missing:
                    return jsonify({'error': f'Missing required fields: {", ".join(missing)}'}), 400
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator

@api_bp.route('/')
def index():
    return render_template('frontend/index.html')

@api_bp.route('/api/register', methods=['POST'])
@validate_json_request(['email', 'username', 'password'])
def register():
    """User registration endpoint with improved error handling"""
    try:
        credentials = request.get_json()
        
        # Input validation
        email = credentials['email'].strip().lower()
        username = credentials['username'].strip()
        password = credentials['password']
        
        # Email format validation
        email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
        if not email_pattern.match(email):
            return jsonify({"message": "Invalid email format"}), 400
        
        # Password strength validation
        if len(password) < 8:
            return jsonify({"message": "Password must be at least 8 characters"}), 400
        
        # Check for existing user
        if User.query.filter_by(email=email).first():
            return jsonify({"message": "User with this email already exists"}), 400
            
        if User.query.filter_by(username=username).first():
            return jsonify({"message": "Username already taken"}), 400
        
        # Create user using Flask-Security's datastore
        # Note: This assumes api_bp.security is properly initialized
        # If not available, use direct User model creation
        try:
            new_user = api_bp.security.datastore.create_user(
                email=email,
                username=username,
                password=password,  # Flask-Security handles hashing
                qualifications=credentials.get('qualification', ''),
                fields_of_interest=credentials.get('fields_of_interest', '')
            )
        except AttributeError:
            # Fallback if security datastore not available
            from werkzeug.security import generate_password_hash
            new_user = User(
                email=email,
                username=username,
                password=generate_password_hash(password),
                qualifications=credentials.get('qualification', ''),
                fields_of_interest=credentials.get('fields_of_interest', '')
            )
            db.session.add(new_user)
        
        db.session.commit()
        logger.info(f"New user registered: {username}")
        return jsonify({"message": "User registered successfully"}), 201
        
    except Exception as e:
        logger.error(f"Registration error: {str(e)}", exc_info=True)
        db.session.rollback()
        return jsonify({"message": "Registration failed. Please try again."}), 500

@api_bp.route('/api/login', methods=['POST'])
@validate_json_request(['email', 'password'])
def login():
    """User login endpoint with improved security"""
    try:
        data = request.get_json()
        email = data['email'].strip().lower()
        password = data['password']

        user = User.query.filter_by(email=email).first()
        
        if user and check_password_hash(user.password, password):
            login_user(user)
            logger.info(f"User logged in: {user.username}")
            return jsonify({
                'message': 'Login successful!',
                'user': {
                    'id': user.id,
                    'username': user.username,
                    'email': user.email
                }
            }), 200
        else:
            # Don't reveal which field is incorrect
            logger.warning(f"Failed login attempt for email: {email}")
            return jsonify({'message': 'Invalid credentials'}), 401
            
    except Exception as e:
        logger.error(f"Login error: {str(e)}", exc_info=True)
        return jsonify({'message': 'Login failed. Please try again.'}), 500

@api_bp.route('/api/edit_profile', methods=['PUT'])
@auth_required('token')
def edit_profile():
    """Update user profile with validation"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'message': 'No data provided'}), 400
            
        user = User.query.get(current_user.id)
        if not user:
            return jsonify({'message': 'User not found'}), 404

        # Update username
        if 'username' in data and data['username'].strip():
            new_username = data['username'].strip()
            existing_user = User.query.filter_by(username=new_username).first()
            if existing_user and existing_user.id != current_user.id:
                return jsonify({'message': 'Username already taken!'}), 400
            user.username = new_username
            
        # Update email
        if 'email' in data and data['email'].strip():
            new_email = data['email'].strip().lower()
            email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
            if not email_pattern.match(new_email):
                return jsonify({'message': 'Invalid email format'}), 400
                
            existing_user = User.query.filter_by(email=new_email).first()
            if existing_user and existing_user.id != current_user.id:
                return jsonify({'message': 'Email already taken!'}), 400
            user.email = new_email
            
        # Update password
        if 'password' in data and data['password']:
            if len(data['password']) < 8:
                return jsonify({'message': 'Password must be at least 8 characters'}), 400
            from werkzeug.security import generate_password_hash
            user.password = generate_password_hash(data['password'])
            
        # Update other fields
        if 'qualifications' in data:
            user.qualifications = data['qualifications']
        if 'fields_of_interest' in data:
            user.fields_of_interest = data['fields_of_interest']

        db.session.commit()
        logger.info(f"Profile updated for user: {user.username}")
        return jsonify({'message': 'Profile updated successfully!'}), 200
        
    except Exception as e:
        logger.error(f"Profile update error: {str(e)}", exc_info=True)
        db.session.rollback()
        return jsonify({'message': 'Profile update failed'}), 500

def is_valid_url(url):
    """Validate URL format and safety"""
    try:
        result = urlparse(url)
        # Check for valid scheme and network location
        if not all([result.scheme, result.netloc]):
            return False
        # Only allow http and https
        if result.scheme not in ['http', 'https']:
            return False
        # Block localhost and private IPs
        blocked_domains = ['localhost', '127.0.0.1', '0.0.0.0', '192.168.', '10.', '172.16.']
        if any(blocked in result.netloc for blocked in blocked_domains):
            return False
        return True
    except Exception:
        return False

def scrape_job_posting(url):
    """Scrape job posting content from URL with improved error handling"""
    if not is_valid_url(url):
        return {'success': False, 'error': 'Invalid or unsafe URL'}
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        # Add timeout and size limit
        response = requests.get(url, headers=headers, timeout=10, stream=True)
        response.raise_for_status()
        
        # Check content size (limit to 5MB)
        content_length = response.headers.get('content-length')
        if content_length and int(content_length) > 5 * 1024 * 1024:
            return {'success': False, 'error': 'Content too large'}
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style", "noscript"]):
            script.decompose()
        
        # Extract text
        text = soup.get_text(separator=' ', strip=True)
        
        # Clean up whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Extract title safely
        title_tag = soup.find('title')
        title = title_tag.get_text(strip=True) if title_tag else 'Unknown'
        
        return {
            'text': text[:5000],  # Limit text length
            'title': title[:200],  # Limit title length
            'success': True
        }
        
    except requests.exceptions.Timeout:
        logger.error(f"Timeout scraping: {url}")
        return {'success': False, 'error': 'Request timeout'}
    except requests.exceptions.RequestException as e:
        logger.error(f"Request error scraping {url}: {str(e)}")
        return {'success': False, 'error': f'Failed to fetch URL: {str(e)}'}
    except Exception as e:
        logger.error(f"Scraping error for {url}: {str(e)}", exc_info=True)
        return {'success': False, 'error': f'Scraping failed: {str(e)}'}

def save_analysis_to_db(url, job_title, company_name, content, analysis_result, detection_method, user_id=None):
    """Save job posting and analysis results to database with transaction safety"""
    try:
        # Sanitize inputs
        url = url[:500] if url else 'Unknown'
        job_title = job_title[:200] if job_title else 'Unknown Position'
        company_name = company_name[:200] if company_name else 'Unknown Company'
        content = content[:5000] if content else ''
        
        # Create job posting
        job_posting = Job_Posting(
            url=url,
            company_name=company_name,
            job_title=job_title,
            job_description=content,
            submitted_at=datetime.utcnow(),
            submitted_by=user_id
        )
        db.session.add(job_posting)
        db.session.flush()
        
        # Determine verdict based on risk score
        risk_score = int(analysis_result.get('risk_score', 0))
        risk_score = max(0, min(100, risk_score))  # Clamp to 0-100
        
        if risk_score >= 70:
            verdict = "Likely Fraudulent"
            risk_level = "High Risk"
        elif risk_score >= 40:
            verdict = "Possibly Fraudulent"
            risk_level = "Medium Risk"
        else:
            verdict = "Appears Legitimate"
            risk_level = "Low Risk"
        
        # Create analysis record
        red_flags = analysis_result.get('red_flags', [])
        analysis = Analysis_Results(
            risk_score=risk_score,
            summary_labels=json.dumps(red_flags[:20]),  # Limit red flags
            verdict=verdict,
            risk_level=risk_level,
            job_id=job_posting.job_id
        )
        db.session.add(analysis)
        db.session.flush()
        
        # Add fraud indicators
        severity_keywords = {
            'Critical': ['payment', 'money', 'bank', 'ssn', 'credit card', 'wire transfer'],
            'High': ['salary', 'website', 'linkedin', 'urgent', 'guarantee'],
            'Medium': ['contact', 'email', 'phone', 'apply now'],
            'Low': []
        }
        
        for flag in red_flags[:10]:  # Limit to 10 indicators
            flag_str = str(flag).lower()
            severity = 'Low'
            
            for sev_level, keywords in severity_keywords.items():
                if any(keyword in flag_str for keyword in keywords):
                    severity = sev_level
                    break
            
            fraud_indicator = Fraud_Indicators(
                indicator_type=str(flag)[:100],
                description=f"Red flag detected: {flag} (Method: {detection_method})"[:500],
                severity_level=severity,
                analysis_id=analysis.analysis_id
            )
            db.session.add(fraud_indicator)
        
        # Update or create company verification
        existing_company = Company_Verification.query.filter_by(
            company_name=company_name
        ).first()
        
        company_info = analysis_result.get('company_legitimacy', {})
        
        if not existing_company:
            company_verification = Company_Verification(
                company_name=company_name,
                linkedin_url=None,
                website_url=company_info.get('website', '')[:500] if company_info.get('website') else None,
                social_presence=bool(company_info.get('linkedin_exists', False)),
                reputation_score=max(0, min(100, 100 - risk_score)),
                is_verified=risk_score < 40,
                website_accessible=bool(company_info.get('website_exists', False)),
                total_jobs_posted=1,
                fraud_jobs_count=1 if risk_score >= 70 else 0
            )
            db.session.add(company_verification)
        else:
            existing_company.total_jobs_posted += 1
            if risk_score >= 70:
                existing_company.fraud_jobs_count += 1
            existing_company.last_checked = datetime.utcnow()
            
            # Weighted average for reputation score
            new_score = 100 - risk_score
            existing_company.reputation_score = int(
                (existing_company.reputation_score * 0.7) + (new_score * 0.3)
            )
        
        db.session.commit()
        
        return {
            'success': True,
            'job_id': job_posting.job_id,
            'analysis_id': analysis.analysis_id
        }
        
    except Exception as e:
        logger.error(f"Database save error: {str(e)}", exc_info=True)
        db.session.rollback()
        return {
            'success': False,
            'error': str(e)
        }

@api_bp.route('/api/analyze', methods=['POST'])
def analyze_job_posting():
    """
    Two-Tier Fraud Detection System with improved error handling
    - 'quick': Fast rule-based analysis (free, instant)
    - 'detailed': Deep LLM-powered analysis (Ollama)
    """
    try:
        # Initialize detectors
        init_detectors()
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'No data provided'}), 400

        # Extract and validate parameters
        job_text = data.get('job_text', '').strip()
        job_url = data.get('job_url', '').strip()
        company_name = data.get('company_name', 'Unknown Company').strip()[:200]
        analysis_type = data.get('analysis_type', 'quick').lower()
        job_title = data.get('job_title', 'Unknown Position').strip()[:200]
        user_id = current_user.id if current_user.is_authenticated else None

        # Validate analysis type
        if analysis_type not in ['quick', 'detailed']:
            return jsonify({'error': 'analysis_type must be "quick" or "detailed"'}), 400

        # Handle URL input
        if job_url:
            if not is_valid_url(job_url):
                return jsonify({'error': 'Invalid or unsafe URL format'}), 400

            logger.info(f"URL provided: {job_url}")

            # Scrape if no text provided
            if not job_text:
                scraped_result = scrape_job_posting(job_url)
                if not scraped_result.get('success'):
                    error_msg = scraped_result.get('error', 'Failed to scrape job posting')
                    return jsonify({'error': error_msg}), 400
                    
                job_text = scraped_result.get('text', '')
                if scraped_result.get('title') and scraped_result['title'] != 'Unknown':
                    job_title = scraped_result['title']
                logger.info(f"Scraped {len(job_text)} characters")
        else:
            # No URL provided
            if not job_text:
                return jsonify({'error': 'Either job_text or job_url must be provided'}), 400
            job_url = 'https://example.com/manual-entry'

        # Validate text length
        if len(job_text) < 50:
            return jsonify({'error': 'Job description too short (minimum 50 characters)'}), 400

        analysis_start = datetime.now()
        final_analysis = None
        detection_method = None

        # Perform analysis based on type
        if analysis_type == 'quick':
            logger.info("Starting QUICK analysis (rule-based)")
            try:
                quick_scan = job_fraud_detector.analyze_job_posting(job_text, job_url)
                analysis_time = (datetime.now() - analysis_start).total_seconds()

                final_analysis = {
                    'risk_score': quick_scan.get('fraud_score', 50),
                    'verdict': quick_scan.get('verdict', 'Unknown'),
                    'risk_level': quick_scan.get('risk_level', 'Medium'),
                    'risk_color': get_risk_color(quick_scan.get('fraud_score', 50)),
                    'red_flags': quick_scan.get('red_flags', []),
                    'company_legitimacy': {'website_exists': False, 'linkedin_exists': False},
                    'scam_result': {'email_flagged': False, 'phone_flagged': False},
                    'llm_analysis': None,
                    'detection_method': 'quick'
                }
                detection_method = 'quick'
            except Exception as e:
                logger.error(f"Quick analysis failed: {e}", exc_info=True)
                return jsonify({'error': 'Quick analysis failed'}), 500

        else:  # detailed analysis
            logger.info("Starting DETAILED analysis (LLM)")
            try:
                ai_analysis = corporate_agent.analyze_job_post(job_text)
                analysis_time = (datetime.now() - analysis_start).total_seconds()

                risk_score = ai_analysis.get('risk_score', 50)
                final_analysis = {
                    'risk_score': risk_score,
                    'verdict': ai_analysis.get('verdict', 'Unknown'),
                    'risk_level': ai_analysis.get('risk_level', 'Medium'),
                    'risk_color': get_risk_color(risk_score),
                    'red_flags': ai_analysis.get('red_flags', []),
                    'company_legitimacy': ai_analysis.get('company_legitimacy', {}),
                    'scam_result': ai_analysis.get('scam_result', {}),
                    'llm_analysis': ai_analysis.get('reasoning', ''),
                    'detection_method': 'detailed'
                }
                detection_method = 'detailed'

            except Exception as e:
                logger.error(f"LLM analysis failed: {e}. Falling back to quick analysis.")
                
                # Fallback to quick analysis
                try:
                    quick_scan = job_fraud_detector.analyze_job_posting(job_text, job_url)
                    analysis_time = (datetime.now() - analysis_start).total_seconds()
                    
                    final_analysis = {
                        'risk_score': quick_scan.get('fraud_score', 50),
                        'verdict': quick_scan.get('verdict', 'Unknown'),
                        'risk_level': quick_scan.get('risk_level', 'Medium'),
                        'risk_color': get_risk_color(quick_scan.get('fraud_score', 50)),
                        'red_flags': quick_scan.get('red_flags', []) + ['âš ï¸ LLM unavailable - used quick scan'],
                        'company_legitimacy': {'website_exists': False, 'linkedin_exists': False},
                        'scam_result': {'email_flagged': False, 'phone_flagged': False},
                        'llm_analysis': None,
                        'detection_method': 'quick_fallback'
                    }
                    detection_method = 'quick_fallback'
                except Exception as fallback_error:
                    logger.error(f"Fallback analysis also failed: {fallback_error}")
                    return jsonify({'error': 'Analysis system unavailable'}), 503

        # Generate auto-reply
        is_scam = final_analysis['risk_score'] >= 60
        try:
            auto_reply = generate_auto_reply(is_scam)
        except Exception:
            auto_reply = "Unable to generate auto-reply at this time."

        # Save to database
        db_result = save_analysis_to_db(
            url=job_url,
            job_title=job_title,
            company_name=company_name,
            content=job_text,
            analysis_result=final_analysis,
            detection_method=detection_method,
            user_id=user_id
        )

        if not db_result.get('success'):
            logger.warning(f"Failed to save to database: {db_result.get('error')}")

        # Build response
        response_data = {
            'risk_score': final_analysis['risk_score'],
            'risk_level': final_analysis['risk_level'],
            'risk_color': final_analysis['risk_color'],
            'verdict': final_analysis['verdict'],
            'is_scam': is_scam,
            'auto_reply': auto_reply,
            'analysis': {
                'red_flags': final_analysis['red_flags'],
                'company_legitimacy': final_analysis['company_legitimacy'],
                'scam_database_check': final_analysis['scam_result'],
                'llm_analysis': final_analysis['llm_analysis'],
                'company_info': {
                    'name': company_name,
                    'website': final_analysis.get('company_legitimacy', {}).get('website')
                }
            },
            'recommendations': generate_recommendations(final_analysis, final_analysis['risk_score']),
            'analysis_type': analysis_type,
            'detection_method': detection_method,
            'database': db_result,
            'performance': {
                'analysis_time': round(analysis_time, 2),
                'method': 'Rule-Based (Fast)' if detection_method.startswith('quick') else 'AI-Powered (Accurate)'
            }
        }

        logger.info(f"âœ… Analysis complete | Type: {analysis_type} | Method: {detection_method} | Score: {final_analysis['risk_score']}")
        return jsonify(response_data), 200

    except Exception as e:
        logger.error(f"Analysis error: {e}", exc_info=True)
        return jsonify({'error': 'Analysis failed. Please try again later.'}), 500

def get_risk_color(risk_score):
    """Determine risk color based on score"""
    if risk_score >= 70:
        return 'danger'
    elif risk_score >= 40:
        return 'warning'
    else:
        return 'success'

def generate_recommendations(analysis_result, risk_score):
    """Generate recommendations based on analysis results"""
    recommendations = []
    
    if risk_score >= 70:
        recommendations.append(" Do not proceed with this job opportunity")
        recommendations.append("Report this posting to the job board immediately")
    elif risk_score >= 60:
        recommendations.append("Exercise extreme caution with this opportunity")
        
    if analysis_result.get('red_flags'):
        recommendations.append("Multiple red flags detected - verify all information independently")
        
    company_legitimacy = analysis_result.get('company_legitimacy', {})
    if not company_legitimacy.get('website_exists'):
        recommendations.append("Company website could not be verified")
        
    if not company_legitimacy.get('linkedin_exists'):
        recommendations.append("Company LinkedIn page not found")
        
    scam_result = analysis_result.get('scam_result', {})
    if scam_result.get('email_flagged') or scam_result.get('phone_flagged'):
        recommendations.append(" Contact information flagged in scam database")
        
    if risk_score < 40:
        recommendations.append(" Job posting appears legitimate, but always verify independently")
        recommendations.append(" Research the company thoroughly before applying")
        recommendations.append(" Verify company details through official channels")
    
    # Suggest detailed analysis for borderline cases
    detection_method = analysis_result.get('detection_method', '')
    if detection_method == 'quick' and 40 <= risk_score < 70:
        recommendations.append("ðŸ’¡ Consider running a detailed analysis for more accurate results")
        
    return recommendations

@api_bp.route('/api/report_scam', methods=['POST'])
@validate_json_request()
def report_scam():
    """API endpoint for reporting scam job postings"""
    try:
        data = request.get_json()
        
        email = data.get('email', '').strip()
        phone = data.get('phone', '').strip()
        additional_info = data.get('additional_info', '').strip()
        
        if not email and not phone:
            return jsonify({'error': 'Either email or phone must be provided'}), 400
        
        # Validate email format if provided
        if email:
            email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
            if not email_pattern.match(email):
                return jsonify({'error': 'Invalid email format'}), 400
        
        # Validate phone format if provided
        if phone:
            phone_clean = re.sub(r'[^\d+]', '', phone)
            if len(phone_clean) < 10:
                return jsonify({'error': 'Invalid phone number'}), 400
        
        add_scam_to_database(email, phone)
        logger.info(f"Scam reported - Email: {email}, Phone: {phone}")
        
        return jsonify({
            'success': True,
            'message': 'Thank you for reporting. The information has been added to our scam database.'
        }), 200
        
    except Exception as e:
        logger.error(f"Report scam error: {str(e)}", exc_info=True)
        return jsonify({'error': 'Failed to report scam'}), 500

@api_bp.route('/api/report', methods=['POST'])
@auth_required('token')
@validate_json_request(['job_id', 'reason'])
def report_job():
    """Community report endpoint for authenticated users"""
    try:
        data = request.get_json()
        
        job_id = data['job_id']
        reason = data['reason'].strip()
        
        if not reason:
            return jsonify({'success': False, 'error': 'Report reason cannot be empty'}), 400
        
        # Check if job exists
        job = Job_Posting.query.get(job_id)
        if not job:
            return jsonify({'success': False, 'error': 'Job not found'}), 404
        
        # Check for duplicate reports from same user
        existing_report = Community_Reports.query.filter_by(
            job_id=job_id,
            user_id=current_user.id
        ).first()
        
        if existing_report:
            return jsonify({
                'success': False,
                'error': 'You have already reported this job'
            }), 400
        
        # Create report
        report = Community_Reports(
            job_id=job_id,
            user_id=current_user.id,
            report_date=datetime.utcnow(),
            report_reason=reason[:500],  # Limit reason length
            user_experience=data.get('experience', '')[:1000]  # Limit experience length
        )
        db.session.add(report)
        
        # Update trending fraud job statistics
        trending = Trending_Fraud_Job.query.filter_by(job_id=job_id).first()
        if trending:
            trending.report_count += 1
            trending.last_updated = datetime.utcnow()
        else:
            trending = Trending_Fraud_Job(
                job_id=job_id,
                report_count=1,
                view_count=0,
                popularity_score=1.0
            )
            db.session.add(trending)
        
        db.session.commit()
        
        logger.info(f"Job {job_id} reported by user {current_user.id}")
        return jsonify({
            'success': True,
            'report_id': report.report_id,
            'message': 'Report submitted successfully'
        }), 200
        
    except Exception as e:
        logger.error(f"Report error: {str(e)}", exc_info=True)
        db.session.rollback()
        return jsonify({'success': False, 'error': 'Failed to submit report'}), 500

@api_bp.route('/api/recent_alerts', methods=['GET'])
def get_recent_alerts():
    """API endpoint for getting recent fraud alerts from database"""
    try:
        # Get limit parameter with default
        limit = request.args.get('limit', default=10, type=int)
        limit = min(max(1, limit), 50)  # Clamp between 1 and 50
        
        recent_analyses = db.session.query(
            Job_Posting, Analysis_Results
        ).join(
            Analysis_Results,
            Job_Posting.job_id == Analysis_Results.job_id
        ).filter(
            Analysis_Results.risk_score >= 60
        ).order_by(
            Job_Posting.submitted_at.desc()
        ).limit(limit).all()
        
        alerts = []
        for job, analysis in recent_analyses:
            time_diff = datetime.utcnow() - job.submitted_at
            hours_ago = int(time_diff.total_seconds() / 3600)
            
            if hours_ago < 1:
                time_str = "Just now"
            elif hours_ago < 24:
                time_str = f'{hours_ago}h ago'
            elif hours_ago < 168:  # Less than a week
                days = int(hours_ago / 24)
                time_str = f'{days}d ago'
            else:
                time_str = job.submitted_at.strftime('%Y-%m-%d')
            
            alerts.append({
                'id': job.job_id,
                'title': job.job_title,
                'description': f'Company: {job.company_name}',
                'risk_level': analysis.risk_level,
                'risk_score': analysis.risk_score,
                'category': 'Job Posting',
                'time_ago': time_str,
                'url': job.url if job.url != 'https://example.com/manual-entry' else None
            })
        
        return jsonify({
            'success': True,
            'alerts': alerts,
            'count': len(alerts)
        }), 200
        
    except Exception as e:
        logger.error(f"Recent alerts error: {str(e)}", exc_info=True)
        return jsonify({'error': 'Failed to fetch recent alerts'}), 500

@api_bp.route('/api/stats', methods=['GET'])
def get_stats():
    """API endpoint for getting fraud detection statistics from database"""
    try:
        # Get total jobs analyzed
        total_analyzed = Job_Posting.query.count()
        
        # Get scams detected (high risk)
        scams_detected = db.session.query(Job_Posting).join(
            Analysis_Results,
            Job_Posting.job_id == Analysis_Results.job_id
        ).filter(
            Analysis_Results.risk_score >= 70
        ).count()
        
        # Get users protected
        users_protected = User.query.count()
        
        # Calculate accuracy rate based on community reports
        try:
            total_reports = Community_Reports.query.count()
            if total_reports > 0:
                # Simple accuracy metric (can be improved)
                accuracy_rate = min(95.0, 85.0 + (total_reports / 100))
            else:
                accuracy_rate = 94.2
        except Exception:
            accuracy_rate = 94.2
        
        stats = {
            'success': True,
            'total_analyzed': total_analyzed,
            'scams_detected': scams_detected,
            'accuracy_rate': round(accuracy_rate, 1),
            'users_protected': users_protected,
            'detection_rate': round((scams_detected / total_analyzed * 100) if total_analyzed > 0 else 0, 1)
        }
        
        return jsonify(stats), 200
        
    except Exception as e:
        logger.error(f"Stats error: {str(e)}", exc_info=True)
        return jsonify({
            'success': False,
            'error': 'Failed to fetch statistics',
            'total_analyzed': 0,
            'scams_detected': 0,
            'accuracy_rate': 94.2,
            'users_protected': 0
        }), 500

@api_bp.route('/api/job/<int:job_id>', methods=['GET'])
def get_job_details(job_id):
    """Get detailed information about a specific job posting"""
    try:
        # Get job with analysis
        job = db.session.query(
            Job_Posting, Analysis_Results
        ).join(
            Analysis_Results,
            Job_Posting.job_id == Analysis_Results.job_id
        ).filter(
            Job_Posting.job_id == job_id
        ).first()
        
        if not job:
            return jsonify({'error': 'Job not found'}), 404
        
        job_posting, analysis = job
        
        # Get fraud indicators
        indicators = Fraud_Indicators.query.filter_by(
            analysis_id=analysis.analysis_id
        ).all()
        
        # Get company verification
        company = Company_Verification.query.filter_by(
            company_name=job_posting.company_name
        ).first()
        
        # Get report count
        report_count = Community_Reports.query.filter_by(
            job_id=job_id
        ).count()
        
        response_data = {
            'success': True,
            'job': {
                'id': job_posting.job_id,
                'title': job_posting.job_title,
                'company': job_posting.company_name,
                'description': job_posting.job_description,
                'url': job_posting.url if job_posting.url != 'https://example.com/manual-entry' else None,
                'submitted_at': job_posting.submitted_at.isoformat()
            },
            'analysis': {
                'risk_score': analysis.risk_score,
                'verdict': analysis.verdict,
                'risk_level': analysis.risk_level,
                'risk_color': get_risk_color(analysis.risk_score)
            },
            'indicators': [
                {
                    'type': ind.indicator_type,
                    'description': ind.description,
                    'severity': ind.severity_level
                } for ind in indicators
            ],
            'company': {
                'name': company.company_name if company else job_posting.company_name,
                'reputation_score': company.reputation_score if company else 0,
                'is_verified': company.is_verified if company else False,
                'total_jobs': company.total_jobs_posted if company else 1,
                'fraud_jobs': company.fraud_jobs_count if company else (1 if analysis.risk_score >= 70 else 0)
            } if company else None,
            'community': {
                'report_count': report_count
            }
        }
        
        return jsonify(response_data), 200
        
    except Exception as e:
        logger.error(f"Get job details error: {str(e)}", exc_info=True)
        return jsonify({'error': 'Failed to fetch job details'}), 500

from application.agent.job_recommendation import get_recommendation_engine

# Add these routes to your api_bp Blueprint

@api_bp.route('/api/recommendations/get', methods=['POST'])
@auth_required('token')
def get_job_recommendations():
    """
    Get personalized job recommendations for authenticated user
    
    Request body:
        {
            "limit": 10,  # optional, default 10
            "include_external": true,  # optional, default true
            "risk_filter": "safe_only"  # optional: "safe_only", "all", "mixed"
        }
    """
    try:
        data = request.get_json() or {}
        
        user_id = current_user.id
        limit = max(1, min(data.get('limit', 10), 50))  # Between 1 and 50
        include_external = data.get('include_external', True)
        risk_filter = data.get('risk_filter', 'safe_only')
        
        # Validate risk filter
        if risk_filter not in ['safe_only', 'all', 'mixed']:
            return jsonify({
                'error': 'risk_filter must be one of: safe_only, all, mixed'
            }), 400
        
        logger.info(f"Getting recommendations for user {user_id}")
        
        # Get recommendation engine
        engine = get_recommendation_engine()
        
        # Get recommendations
        recommendations = engine.get_recommendations(
            user_id=user_id,
            limit=limit,
            include_external=include_external,
            risk_filter=risk_filter
        )
        
        # Get user stats
        stats = engine.get_user_stats(user_id)
        
        # Calculate statistics
        safe_count = sum(1 for r in recommendations if r.get('risk_score', 0) <= 30)
        risky_count = len(recommendations) - safe_count
        
        response = {
            'success': True,
            'user_id': user_id,
            'recommendations': recommendations,
            'count': len(recommendations),
            'parameters': {
                'limit': limit,
                'include_external': include_external,
                'risk_filter': risk_filter
            },
            'statistics': {
                'safe_jobs': safe_count,
                'risky_jobs': risky_count,
                'total': len(recommendations)
            },
            'user_profile': stats
        }
        
        return jsonify(response), 200
        
    except Exception as e:
        logger.error(f"Recommendation error: {e}", exc_info=True)
        return jsonify({'error': 'Failed to get recommendations'}), 500


@api_bp.route('/api/recommendations/profile', methods=['GET'])
@auth_required('token')
def get_recommendation_profile():
    """Get user's recommendation profile and statistics"""
    try:
        user_id = current_user.id
        
        engine = get_recommendation_engine()
        stats = engine.get_user_stats(user_id)
        
        # Get user preferences
        user_prefs = engine.get_user_preferences(user_id)
        
        response = {
            'success': True,
            'user_id': user_id,
            'profile': stats,
            'preferences': {
                'qualifications': user_prefs['qualifications'] if user_prefs else [],
                'interests': user_prefs['interests'] if user_prefs else []
            },
            'recommendations_enabled': stats['jobs_analyzed'] > 0 or (user_prefs and (user_prefs['qualifications'] or user_prefs['interests']))
        }
        
        return jsonify(response), 200
        
    except Exception as e:
        logger.error(f"Profile error: {e}", exc_info=True)
        return jsonify({'error': 'Failed to get profile'}), 500


@api_bp.route('/api/recommendations/history', methods=['GET'])
@auth_required('token')
def get_recommendation_history():
    """Get user's job browsing history for recommendations"""
    try:
        user_id = current_user.id
        limit = request.args.get('limit', default=50, type=int)
        limit = min(max(1, limit), 100)  # Between 1 and 100
        
        engine = get_recommendation_engine()
        history = engine.get_user_browsing_history(user_id, limit=limit)
        
        response = {
            'success': True,
            'user_id': user_id,
            'history': history,
            'count': len(history)
        }
        
        return jsonify(response), 200
        
    except Exception as e:
        logger.error(f"History error: {e}", exc_info=True)
        return jsonify({'error': 'Failed to get history'}), 500


@api_bp.route('/api/recommendations/suggest', methods=['POST'])
def get_public_recommendations():
    """
    Get job recommendations for non-authenticated users based on query
    
    Request body:
        {
            "query": "software engineer",  # required
            "location": "Remote",  # optional, default "Remote"
            "limit": 10  # optional, default 10
        }
    """
    try:
        data = request.get_json()
        if not data or 'query' not in data:
            return jsonify({'error': 'query is required'}), 400
        
        query = data['query'].strip()
        location = data.get('location', 'Remote')
        limit = max(1, min(data.get('limit', 10), 20))  # Between 1 and 20
        
        if not query:
            return jsonify({'error': 'query cannot be empty'}), 400
        
        logger.info(f"Public recommendation request: {query}")
        
        engine = get_recommendation_engine()
        
        # Search external jobs
        jobs = engine._search_external_jobs(query, location, limit=limit)
        
        # Calculate basic match score (since no user profile)
        for job in jobs:
            # Simple relevance based on query match
            job_text = f"{job['title']} {job.get('description', '')}".lower()
            query_words = query.lower().split()
            matches = sum(1 for word in query_words if word in job_text)
            job['match_score'] = (matches / len(query_words)) * 100 if query_words else 0
            job['risk_score'] = 15  # Default safe assumption for external sources
            job['risk_level'] = 'Low Risk'
        
        # Sort by match score
        jobs = sorted(jobs, key=lambda x: x['match_score'], reverse=True)
        
        response = {
            'success': True,
            'query': query,
            'location': location,
            'jobs': jobs,
            'count': len(jobs),
            'note': 'Sign in for personalized recommendations based on your profile'
        }
        
        return jsonify(response), 200
        
    except Exception as e:
        logger.error(f"Public recommendation error: {e}", exc_info=True)
        return jsonify({'error': 'Failed to get recommendations'}), 500


@api_bp.route('/api/recommendations/refresh', methods=['POST'])
@auth_required('token')
def refresh_recommendations():
    """
    Refresh user's ML profile and get new recommendations
    Useful after user has analyzed multiple new jobs
    """
    try:
        user_id = current_user.id
        
        engine = get_recommendation_engine()
        
        # Rebuild ML profile
        ml_profile = engine.build_user_profile(user_id)
        
        if not ml_profile:
            return jsonify({
                'success': False,
                'message': 'Not enough job history to build ML profile. Analyze at least 3 jobs first.'
            }), 400
        
        # Get fresh recommendations
        recommendations = engine.get_recommendations(
            user_id=user_id,
            limit=15,
            include_external=True,
            risk_filter='safe_only'
        )
        
        response = {
            'success': True,
            'message': 'Profile refreshed and recommendations updated',
            'user_id': user_id,
            'ml_profile': ml_profile,
            'recommendations': recommendations,
            'count': len(recommendations)
        }
        
        return jsonify(response), 200
        
    except Exception as e:
        logger.error(f"Refresh error: {e}", exc_info=True)
        return jsonify({'error': 'Failed to refresh recommendations'}), 500


@api_bp.route('/api/recommendations/stats', methods=['GET'])
def get_recommendation_stats():
    """Get global recommendation statistics (public endpoint)"""
    try:
        # Total jobs in database
        total_jobs = Job_Posting.query.count()
        
        # Safe jobs (low risk)
        safe_jobs = db.session.query(Job_Posting).join(
            Analysis_Results,
            Job_Posting.job_id == Analysis_Results.job_id
        ).filter(
            Analysis_Results.risk_score <= 30
        ).count()
        
        # Users with browsing history
        users_with_history = db.session.query(
            Job_Posting.submitted_by
        ).filter(
            Job_Posting.submitted_by.isnot(None)
        ).distinct().count()
        
        # Average risk score of all analyzed jobs
        avg_risk_score = db.session.query(
            func.avg(Analysis_Results.risk_score)
        ).scalar() or 0
        
        stats = {
            'success': True,
            'total_jobs_analyzed': total_jobs,
            'safe_jobs_available': safe_jobs,
            'users_with_profiles': users_with_history,
            'average_risk_score': round(float(avg_risk_score), 2),
            'recommendation_engine': 'ML-Powered with TF-IDF',
            'features': [
                'Personalized recommendations',
                'ML-based profile building',
                'External job board integration',
                'Risk-filtered results',
                'Real-time fraud detection'
            ]
        }
        
        return jsonify(stats), 200
        
    except Exception as e:
        logger.error(f"Stats error: {e}", exc_info=True)
        return jsonify({'error': 'Failed to get statistics'}), 500


@api_bp.route('/api/recommendations/similar/<int:job_id>', methods=['GET'])
def get_similar_jobs(job_id):
    """
    Get jobs similar to a specific job (public endpoint)
    Useful for "You might also like" feature
    """
    try:
        # Get the target job
        job = Job_Posting.query.get(job_id)
        if not job:
            return jsonify({'error': 'Job not found'}), 404
        
        # Get similar safe jobs from database
        similar_jobs = db.session.query(
            Job_Posting, Analysis_Results
        ).join(
            Analysis_Results,
            Job_Posting.job_id == Analysis_Results.job_id
        ).filter(
            Job_Posting.job_id != job_id,
            Analysis_Results.risk_score <= 30
        ).order_by(
            Analysis_Results.risk_score.asc()
        ).limit(10).all()
        
        results = []
        for similar_job, analysis in similar_jobs:
            # Calculate similarity based on keywords
            target_keywords = set(job.job_title.lower().split() + job.job_description.lower().split())
            similar_keywords = set(similar_job.job_title.lower().split() + similar_job.job_description.lower().split())
            
            # Jaccard similarity
            intersection = len(target_keywords & similar_keywords)
            union = len(target_keywords | similar_keywords)
            similarity_score = (intersection / union * 100) if union > 0 else 0
            
            results.append({
                'job_id': similar_job.job_id,
                'title': similar_job.job_title,
                'company': similar_job.company_name,
                'description': similar_job.job_description[:200],
                'url': similar_job.url if similar_job.url != 'https://example.com/manual-entry' else None,
                'risk_score': analysis.risk_score,
                'risk_level': analysis.risk_level,
                'similarity_score': round(similarity_score, 2)
            })
        
        # Sort by similarity
        results = sorted(results, key=lambda x: x['similarity_score'], reverse=True)[:5]
        
        response = {
            'success': True,
            'reference_job': {
                'id': job.job_id,
                'title': job.job_title,
                'company': job.company_name
            },
            'similar_jobs': results,
            'count': len(results)
        }
        
        return jsonify(response), 200
        
    except Exception as e:
        logger.error(f"Similar jobs error: {e}", exc_info=True)
        return jsonify({'error': 'Failed to get similar jobs'}), 500
        
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}")
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

# Error handlers
@api_bp.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Resource not found'}), 404

@api_bp.errorhandler(405)
def method_not_allowed(error):
    return jsonify({'error': 'Method not allowed'}), 405

@api_bp.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {str(error)}", exc_info=True)
    db.session.rollback()
    return jsonify({'error': 'Internal server error'}), 500